%=============================================================================
\subsection{Feature Transformation Stack}
\label{sec:feature-stack}

\textbf{Stack overview:} Transform, combine, and refine representational features. Perform nonlinear feature composition, extract abstract concepts, and implement representational changes. Enable complex feature interactions and hierarchical abstraction.

\textbf{MLP Characterization Note:} Mechanisms in this stack are characterized primarily through behavioral evidence and theoretical understanding of MLP function. Unlike attention-based mechanisms, MLP computations lack the same degree of circuit-level tracing. These mechanisms describe computational functions inferred from behavior, ablation studies, and architectural analysis rather than fully traced circuits. Only Nonlinear Composition achieves Tier 1 status through extensive evidence; the other mechanisms remain at Tier 2 pending more detailed mechanistic characterization.

%-----------------------------------------------------------------------------
\subsubsection{Nonlinear Composition Mechanism}
\label{mech:nonlinear-composition}

\noindent\depthinfo{0.20--0.80 (E-L)} | \primaryimpl{MLP neurons} | \litnames{feature mixing, nonlinear transformation, hidden layer processing}

\begin{functiondesc}
Perform nonlinear combinations and transformations of input features. Implement the core MLP computation: expand dimensionality ($d \to 4d$), apply nonlinearity (GELU/ReLU), contract ($4d \to d$). Enable complex feature interactions impossible through linear attention alone. Create new feature combinations not present in input. Support hierarchical feature refinement: surface features (early layers) to abstract concepts (late layers). Universal approximation capability within residual stream constraints. Foundation for all MLP-based computation.
\end{functiondesc}

\begin{implementationbox}
\mlpimpl{MLP layers (all depths, 0.20--0.80) implement universal computation through two-layer transformation. First sublayer: expand to higher dimension and detect feature combinations through learned weight patterns. Nonlinearity (GELU/ReLU): enable complex interactions beyond linear combinations. Second sublayer: project back to residual stream dimension with newly composed features.}\\
\circuitimpl{Interleaved with attention throughout depth: attention routes information $\rightarrow$ MLP transforms features $\rightarrow$ attention routes transformed features. Hierarchical refinement across layers. Fundamental to all feature-based computation.}
\end{implementationbox}

\begin{ablationbox}
\textbf{Expected ablation:} Severe degradation in complex reasoning and feature interactions. Loss of nonlinear transformations reduces model to near-linear operation. Major impact on abstract concept formation and semantic understanding. Model becomes significantly less expressive. Reduced ability to combine multiple features simultaneously. Critical loss of representational power.
\end{ablationbox}

\begin{examplebox}
\exinput{Features: [``large'', ``gray'', ``trunk'', ``tusks'']}\\
\exbehavior{Expand features, apply nonlinear combinations through MLP transformation, detect co-occurrence patterns}\\
\exeffect{Create ``elephant'' representation through nonlinear feature composition}
\end{examplebox}

\mechfooter{\statuswell}{abstract-concept-formation, factual-recall}

%-----------------------------------------------------------------------------
\subsubsection{Abstract Concept Formation Mechanism}
\label{mech:abstract-concepts}

\noindent\depthinfo{0.50--0.80 (M-L)} | \primaryimpl{MLP neurons} | \litnames{abstraction, concept extraction, semantic generalization}

\begin{functiondesc}
Extract and represent abstract concepts from concrete features. Perform semantic generalization: map specific instances to general categories. Build hierarchical abstractions through depth: words $\rightarrow$ phrases $\rightarrow$ concepts $\rightarrow$ themes. Enable reasoning at multiple levels of abstraction. Support metaphor, analogy, and transfer learning. Transform surface-level tokens into deep semantic representations. Increase abstraction level with layer depth: early layers process concrete features, late layers encode high-level themes.
\end{functiondesc}

\begin{implementationbox}
\mlpimpl{Abstraction neurons (M-L, 0.50--0.80) encode increasingly abstract concepts at greater depths. Hierarchical organization: Early layers represent concrete features. Middle layers encode category-level abstractions and semantic classes. Late layers represent high-level themes, relationships, and domain concepts.}\\
\circuitimpl{Progressive abstraction across layers. Attention at each level operates on abstractions appropriate to that depth. Supports analogical reasoning and transfer through shared abstract representations.}
\end{implementationbox}

\begin{ablationbox}
\textbf{Expected ablation:} Significant loss of abstract reasoning capability. Difficulty with generalization and category-level thinking. Notable degradation on tasks requiring conceptual understanding beyond literal meaning. Reduced ability to recognize analogies and metaphors. More concrete, less flexible reasoning patterns. Impaired transfer learning within context.
\end{ablationbox}

\begin{examplebox}
\exinput{``The stock market crashed. Housing prices collapsed. Banks failed.''}\\
\exbehavior{Extract abstract concept of ``financial crisis'' from specific event instances through hierarchical abstraction}\\
\exeffect{Enable reasoning about crisis in general, not just specific instances mentioned}
\end{examplebox}

\mechfooter{\statusobs}{nonlinear-composition, semantic-integration}

\begin{openquestionsbox}
\textbf{MLP circuit tracing needed:} While behavioral evidence for hierarchical abstraction is strong, detailed circuit-level understanding remains incomplete. Future research should trace information flow through MLP layers, identify specific neuron populations encoding different abstraction levels, and distinguish this mechanism from general nonlinear composition capabilities.
\end{openquestionsbox}

%-----------------------------------------------------------------------------
\subsubsection{Semantic Integration Mechanism}
\label{mech:semantic-integration}

\noindent\depthinfo{0.40--0.70 (M-L)} | \primaryimpl{MLP neurons + Attention heads} | \litnames{meaning composition, semantic synthesis, contextual integration}

\begin{functiondesc}
Integrate semantic information from multiple sources to build coherent meaning representations. Combine word meanings with context to resolve ambiguity. Perform compositional semantics: build phrase and sentence meanings from word-level components. Resolve polysemy and homonymy using contextual information. Enable context-dependent interpretation of ambiguous terms. Support pragmatic inference and implicature understanding. Distinguish from memory consolidation (knowledge-level) and context aggregation (discourse-level).
\end{functiondesc}

\begin{implementationbox}
\mlpimpl{Semantic integration neurons (M-L, 0.45--0.70) combine contextual information to disambiguate and refine meanings. Store semantic composition patterns and context-dependent interpretation rules.}\\
\attnimpl{Context-gathering heads (M, 0.40--0.60) collect relevant semantic information from surrounding context for disambiguation and meaning construction.}\\
\circuitimpl{Context gathering (M) $\rightarrow$ MLP semantic composition (M-L) $\rightarrow$ refined meaning representations. Enables compositional semantics through coordinated attention and transformation.}
\end{implementationbox}

\begin{ablationbox}
\textbf{Expected ablation:} Moderate loss of context-dependent meaning resolution. Increased ambiguity in interpretation of polysemous terms. Notable degradation on homonym disambiguation and context-sensitive understanding. More literal, less nuanced comprehension. Reduced ability to perform compositional semantics. Difficulty with pragmatic inference.
\end{ablationbox}

\begin{examplebox}
\exinput{``The bank was steep'' vs. ``The bank was closed''}\\
\exbehavior{Integrate context clues (``steep'' vs. ``closed'') to disambiguate ``bank'' meaning through semantic integration}\\
\exeffect{Correctly interpret as river bank vs. financial institution based on contextual semantics}
\end{examplebox}

\mechfooter{\statusobs}{abstract-concepts, factual-recall}

\begin{openquestionsbox}
\textbf{Compositional semantics characterization needed:} Mechanism inferred from behavioral patterns and theoretical understanding of semantic composition. Detailed mechanistic evidence for how MLP neurons implement compositional semantics and context-dependent disambiguation remains limited. SAE-based analysis of semantic features could provide deeper insight.
\end{openquestionsbox}
